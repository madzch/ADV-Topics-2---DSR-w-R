read_csv("MFIndD_analogy.csv") #renamed
analogy_data <- read_csv("Analogy_Dataset.csv")
knitr::opts_knit$set(root.dir = "~/GitHub/ADV-Topics-2---DSR-w-R/WeeklyAssignments/tidy_data")
#had to be added for working dir issues, now fixed
rei_summary <- new_score %>%
filter(sub_type %in% c("EA", "EE", "RE", "RA")) %>% # Keep only relevant sub_types
group_by(qualtrics_id, sub_type) %>%
summarise(score = sum(new_scored_response), #na.rm = TRUE),
.groups = 'drop')
rei_summary <- new_score %>%
filter(sub_type %in% c("EA", "EE", "RE", "RA")) %>% # Keep only relevant sub_types
group_by(qualtrics_id, sub_type) %>%
summarise(score = sum(new_scored_response, na.rm = FALSE), .groups = 'drop')
rei_summary <- new_score %>%
filter(sub_type %in% c("EA", "EE", "RE", "RA")) %>% # Keep only relevant sub_types
group_by(qualtrics_id, sub_type) %>%
summarise(score = sum(new_scored_response, na.rm = FALSE), .groups = 'drop')
library(tidyverse)
rei_summary <- new_score %>%
filter(sub_type %in% c("EA", "EE", "RE", "RA")) %>% # Keep only relevant sub_types
group_by(qualtrics_id, sub_type) %>%
summarise(score = sum(new_scored_response, na.rm = FALSE), .groups = 'drop')
# Check the summary to confirm it has the right number of rows
#print(complete_rei_summary)
rei_summary
#Question 1b
rei_summary <- new_score %>%
filter(sub_type %in% c("EA", "EE", "RE", "RA")) %>% # Keep only relevant sub_types
group_by(qualtrics_id, sub_type) %>%
summarise(score = sum(new_scored_response, na.rm = FALSE), .groups = 'drop')
#The above code chunk is similar to this one here.The only difference is that the na.rm status is set to default where na.rm = false. There are indeed NA values, and I will summarize them in the following code chunk.
rei_summary
#Question 1b (part two)
na_filter <- rei_summary
filter(is.na (na_filter))
#Question 1b (part two)
na_filter <- rei_summary
filtered <-is.na(na_filter)
#Question 1b (part two)
na_filter <- rei_summary
filtered <-is.na(na_filter)
filtered
#Question 1b (part two)
na_filter <- rei_summary
filtered <- is.na(filter(na_filter))
filtered
#Question 1b (part two)
na_filter <- rei_summary
filtered <- is.na(filter(na_filter)) = TRUE
#Question 1b (part two)
na_filter <- rei_summary
filtered <- is.na(filter(na_filter)= TRUE )
#Question 1b (part two)
na_filter <- rei_summary
filtered <- is.na(filter(na_filter)== TRUE )
filtered
#Question 1b (part two)
na_filter <- rei_summary
filtered <- is.na(filter(na_filter)== TRUE )
summarize (filtered == TRUE)
#Question 1b (part two)
na_filter <- rei_summary
filtered <- is.na(filter(na_filter)== TRUE )
summarize (filtered)
#Question 1b (part two)
na_filter <- rei_summary
filtered <- is.na(filter(na_filter)== TRUE )
summarize (filtered)
#Question 1b (part two)
na_filter <- rei_summary
filtered <- filter(if_any(na_filter,is.na)
summarize (filtered)
#Question 1b (part two)
na_filter <- rei_summary
filtered <- filter(if_any(na_filter,is.na)
#Question 1b (part two)
na_filter <- rei_summary
filtered <- filter(if_any(na_filter,is.na))
#Question 1b (part two)
na_filter <- rei_summary
filtered <- groupby( qualtrics_id,
filter(if_any(na_filter,is.na))
)
#Question 1b (part two)
na_filter <- rei_summary
filtered <- group_by( qualtrics_id,
filter(if_any(na_filter,is.na))
)
knitr::opts_knit$set(root.dir = "~/GitHub/ADV-Topics-2---DSR-w-R/WeeklyAssignments/tidy_data")
#had to be added for working dir issues, now fixed
#in order to load the tidyverse library you must run the following
library(tidyverse)
?tidyverse
#Below is the provided description after running #?tidyverse
read_csv("MFIndD_analogy.csv") #renamed
#Question 1b (part two)
na_filter <- rei_summary
filtered <- group_by(
filter(if_any(na_filter,is.na))
)
#Question 1b (part two)
na_filter <- rei_summary%>%
filtered <- group_by(
filter(if_any(na_filter,is.na))
)
#Question 1b (part two)
na_filter <- rei_summary%>%
filtered <- group_by(qualtrics_id
filter(if_any(na_filter,is.na))
#Question 1b (part two)
na_filter <- rei_summary%>%
group_by(qualtrics_id,
filter(if_any(na_filter,is.na)))
#Question 1b (part two)
na_filter <- rei_summary%>%
group_by(qualtrics_id,
filter(if_any(na_filter,is.na(score))))
#Question 1b (part two)
rei_summary%>%
group_by(qualtrics_id,
filter(if_any(na_filter,is.na(score))))
#Question 1b (part two)
rei_summary%>%
filter(if_any(na_filter,is.na(score))))
#Question 1b (part two)
rei_summary%>%
filter(if_any(na_filter,is.na(score)))
# Question 1a
rei_summary <- new_score %>%
filter(sub_type %in% c("EA", "EE", "RE", "RA")) %>% # Keep only relevant sub_types
group_by(qualtrics_id, sub_type) %>%
summarise(score = sum(new_scored_response, na.rm = TRUE), .groups = 'drop')
# Check the summary to confirm it has the right number of rows
rei_summary
#Question 1b (part 1)
rei_summary <- new_score %>%
filter(sub_type %in% c("EA", "EE", "RE", "RA")) %>% # Keep only relevant sub_types
group_by(qualtrics_id, sub_type) %>%
summarise(score = sum(new_scored_response, na.rm = FALSE), .groups = 'drop')
#The above code chunk is similar to this one here.The only difference is that the na.rm status is set to default where na.rm = false. There are indeed NA values scattered throughout, and I will summarize them in the following code chunk.
rei_summary
#Question 1b (part two)
rei_summary%>%
filter(if_any(na_filter,is.na(score)))
#Question 1b (part two)
rei_summary%>%
filter(is.na(score))
library(tidyverse)
#items that need to be scored are marked as "neg" if not then marked with "NA"
new_score <- dbl_response%>%
mutate(new_scored_response = if_else(
rev_scoring == "neg", 6 - response_dbl,
response_dbl,
missing = response_dbl # this should account for all of the NA values
))
new_score
new_score <- new_score %>%
mutate(is_equal = new_scored_response == scored_response)
# To check how many rows are not equal,filter those mismatches
mismatch_count <- new_score %>%
filter(is_equal == FALSE) %>%
count()
# View the count of mismatches
mismatch_count
# Question 1a
rei_summary <- new_score %>%
filter(sub_type %in% c("EA", "EE", "RE", "RA")) %>% # Keep only relevant sub_types
group_by(qualtrics_id, sub_type) %>%
summarise(score = sum(new_scored_response, na.rm = TRUE), .groups = 'drop')
# Check the summary to confirm it has the right number of rows
rei_summary
#Question 1b (part 1)
rei_summary <- new_score %>%
filter(sub_type %in% c("EA", "EE", "RE", "RA")) %>% # Keep only relevant sub_types
group_by(qualtrics_id, sub_type) %>%
summarise(score = sum(new_scored_response, na.rm = FALSE), .groups = 'drop')
#The above code chunk is similar to this one here.The only difference is that the na.rm status is set to default where na.rm = false. There are indeed NA values scattered throughout, and I will summarize them in the following code chunk.
rei_summary
#Question 1b (part two)
rei_summary%>%
filter(is.na(score))
#This represents all people who have no "score" recorded for the respective trial(from the summary).
# 1c Here I'll switch the na.rm "condition" back to true as I had it in my original (first code snippet) which I will replicate down below. This will assure that the scores are calculated and represented properly.
rei_summary <- new_score %>%
filter(sub_type %in% c("EA", "EE", "RE", "RA")) %>% # Keep only relevant sub_types
group_by(qualtrics_id, sub_type) %>%
summarise(score = sum(new_scored_response, na.rm = TRUE), .groups = 'drop')
# 1c Here I'll switch the na.rm "condition" back to true as I had it in my original (first code snippet) which I will replicate down below. This will assure that the scores are calculated and represented properly.
rei_summary <- new_score %>%
filter(sub_type %in% c("EA", "EE", "RE", "RA")) %>% # Keep only relevant sub_types
group_by(qualtrics_id, sub_type) %>%
summarise(score = sum(new_scored_response, na.rm = TRUE), .groups = 'drop')
rei_summary
?join_by
# 2 Combining the summarized datasets from analogy and rei(that we just finished):
left_join(rei_summary, num_of_trials, by = qualtrics_id)
# 2 Combining the summarized datasets from analogy and rei(that we just finished):
left_join(rei_summary, num_of_trials, by = NULL)
# 2 Combining the summarized datasets from analogy and rei(that we just finished):
left_join(rei_summary,reshaped_data, by = NULL)
# 2 Combining the summarized datasets from analogy and rei(that we just finished):
left_join(rei_summary,reshaped_data, by = NULL)
library(tidyverse)
Analogy_Dataset.csv <- analogy_data #%>%
reshaped_data <- analogy_data %>%
select(qualtrics_id, trial_number, response_type) %>%   # Select relevant columns
filter(trial_number <= 8) %>%                          # Keep only the first 8 trials
pivot_wider(names_from = trial_number,                 # Reshape from long to wide format
values_from = response_type,
names_prefix = "trial_") %>%               # Rename trials to trial_1, trial_2, etc.
select(qualtrics_id,trial_1, trial_2, trial_3, trial_4, trial_5, trial_6, trial_7, trial_8) # Ensure only 9 columns (ID + 8 trials) and put them in order!
reshaped_data
# 1c Here I'll switch the na.rm "condition" back to true as I had it in my original (first code snippet) which I will replicate down below. This will assure that the scores are calculated and represented properly.
rei_summary <- new_score %>%
filter(sub_type %in% c("EA", "EE", "RE", "RA")) %>% # Keep only relevant sub_types
group_by(qualtrics_id, sub_type) %>%
summarise(score = sum(new_scored_response, na.rm = TRUE), .groups = 'drop')
rei_summary
# 2 Combining the summarized datasets from analogy and rei(that we just finished):
left_join(rei_summary,reshaped_data, by = NULL)
# 2 Combining the summarized datasets from analogy and rei(that we just finished):
left_join(rei_summary,num_of_trials, by = NULL)
# 2 Combining the summarized datasets from analogy and rei(that we just finished):
left_join(rei_summary,num_of_trials, by = NULL) <- combined_data
# 2 Combining the summarized datasets from analogy and rei(that we just finished):
combined_data <- left_join(rei_summary,num_of_trials, by = NULL) <- combined_data
# 2 Combining the summarized datasets from analogy and rei(that we just finished):
left_join(rei_summary,num_of_trials, by = NULL) <- combined_data
# 2 Combining the summarized datasets from analogy and rei(that we just finished):
left_join(rei_summary,num_of_trials, by = NULL) %>%
combined_data
# 2 Combining the summarized datasets from analogy and rei(that we just finished):
left_join(rei_summary,num_of_trials, by = NULL) <-
combined_data
# 2 Combining the summarized datasets from analogy and rei(that we just finished):
joined_data <- left_join(rei_summary,num_of_trials, by = NULL)
#num_trials is the number of trials that the corresponding person (qualtrics_id) responded with "Rel".
# 2 Combining the summarized datasets from analogy and rei(that we just finished):
joined_data <- left_join(rei_summary,num_of_trials, by = qualtrics_id)
# 2 Combining the summarized datasets from analogy and rei(that we just finished):
joined_data <- left_join(rei_summary,num_of_trials, by = qualtrics)
# 2 Combining the summarized datasets from analogy and rei(that we just finished):
joined_data <- left_join(rei_summary,num_of_trials, by = qualtrics_id)
# 2 Combining the summarized datasets from analogy and rei(that we just finished):
joined_data <- left_join(rei_summary,num_of_trials, by = NULL)
#num_trials is the number of trials that the corresponding person (qualtrics_id) responded with "Rel".
# 2 Combining the summarized datasets from analogy and rei(that we just finished):
joined_data <- left_join(rei_summary,num_of_trials, by = ('qualtrics_id'))
#num_trials is the number of trials that the corresponding person (qualtrics_id) responded with "Rel".
# 2 Combining the summarized datasets from analogy and rei(that we just finished):
joined_data <- left_join(rei_summary,num_of_trials, by = ('qualtrics_id'))
#num_trials is the number of trials that the corresponding person (qualtrics_id) responded with "Rel".
joined_data
# Scatterplot for relationship between REI score and newscore
ggplot(joined_data, aes(x = score, y = num_of_trials, color = sub_type)) +
geom_point() +
geom_smooth(method = "lm") +
labs(title = "REI Scores by Subtype",
x = "Sub Type", y = "Total Score") +
theme_minimal()
# Scatterplot for relationship between REI score and newscore
ggplot(joined_data, aes(x = score, y = num_of_trials, color = sub_type)) +
geom_point() +
geom_smooth(method = "lm") +
labs(title = "REI Scores by Subtype",
x = "Sub Type Scores", y = " Number of Rel responses") +
theme_minimal()
# Scatterplot for relationship between REI score and newscore
ggplot(joined_data, aes(x = num_of_trials, y = score, color = sub_type)) +
geom_point() +
geom_smooth(method = "lm") +
labs(title = "REI Scores by Subtype",
y = "Sub Type Scores", x = " Number of Rel responses") +
theme_minimal()
# Scatterplot for relationship between REI score and newscore
ggplot(joined_data, aes(x = num_of_trials, y = score, color = sub_type)) +
geom_point() +
geom_smooth(method = "lm") +
labs(title = "REI Scores by Subtype",
y = " Sum of Sub Type Scores", x = " Number of Rel responses") +
theme_minimal()
getwd()
knitr::opts_knit$set(root.dir = "~/GitHub/ADV-Topics-2---DSR-w-R/WeeklyAssignments/tidy_data")
#had to be added for working dir issues, now fixed
magic_ball <- read_csv("MFindD_probtask.csv")
library(tidyverse)
magic_ball <- read_csv("MFindD_probtask.csv")
magic_ball
magic_ball %>%
filter(distinct(condition))
magic_ball %>%
filter(distinct("condition"))
magic_ball %>%
(distinct("condition"))
?pull
unique_conditions <- magic_ball %>% distinct(conditions) %>%
pull(conditions)
magic_ball <- read_csv("MFindD_probtask.csv")
magic_ball
unique_conditions <- magic_ball %>% distinct(conditions) %>%
pull(conditions)
magic_ball %>%
distinct(conditions) %>%
pull(conditions)
magic_ball %>%
distinct("conditions") %>%
pull("conditions")
unique_conditions <- magic_ball %>% distinct(condition) %>%
pull(condition)
#distinct conditions values
unique_conditions <- magic_ball %>% distinct(condition) %>%
pull(condition)
#distinct conditions values
unique_conditions
mean_reaction_times <- c()
for (cond in unique_conditions) {
mean_reaction_time <- magic_ball %>% filter(conditions == cond) %>% summarize(mean_reaction = mean(reaction_time, na.rm = TRUE)) %>% pull(mean_reaction)
mean_reaction_times <- c(mean_reaction_times, mean_reaction_time)
}
mean_reaction_times <- c()
for (cond in unique_conditions) {
mean_reaction_time <- magic_ball %>% filter(condition == cond) %>% summarize(mean_reaction = mean(reaction_time, na.rm = TRUE)) %>% pull(mean_reaction)
mean_reaction_times <- c(mean_reaction_times, mean_reaction_time)
}
mean_reaction_times <- c()
for (cond in unique_conditions) {
mean_reaction_time <- magic_ball %>% filter(condition == cond) %>% summarize(mean_reaction = mean(rt, na.rm = TRUE)) %>% pull(mean_reaction)
mean_reaction_times <- c(mean_reaction_times, mean_reaction_time)
}
names(mean_reaction_times) <- unique_conditions
mean_reaction_times
# using across
magic_ball %>%
group_by(condition) %>%
summarise(across(c(mean_reaction_time, correct),
list(mean = mean,
overall_accuracy = ~mean(.==TRUE)),
.names = "{col}_{fn}" ))
# using across
names(mean_reaction_times)%>%
group_by(condition) %>%
summarise(across(c(mean_reaction_times, correct),
list(mean = mean,
overall_accuracy = ~mean(.==TRUE)),
.names = "{col}_{fn}" ))
# using across
magic_ball %>%
group_by(condition) %>%
summarise(across(c(mean_reaction_time, correct),
list(mean = mean,
overall_accuracy = ~mean(.==TRUE)),
.names = "{col}_{fn}" ))
# using across
magic_ball %>%
group_by(condition) %>%
summarise(across(where(is.numeric),
list(mean = ~mean(.),
overall_accuracy = ~mean(. == TRUE)),
.names = "{col}_{fn}"))
# using across
magic_ball %>%
group_by(condition) %>%
summarise(mean_reaction_time = mean(reaction_time),
overall_accuracy = mean(correct))
# using across
magic_ball %>%
group_by(condition) %>%
summarise(mean_reaction_time = mean(rt),
overall_accuracy = mean(correct))
# using across
summary_df <- magic_ball %>%
group_by(condition) %>%
summarise(mean_reaction_time = mean(reaction_time, na.rm = TRUE),
overall_accuracy = mean(correct, na.rm = TRUE))
# using across
summary_df <- magic_ball %>%
group_by(condition) %>%
summarise(mean_reaction_time = mean(rt, na.rm = TRUE),
overall_accuracy = mean(correct, na.rm = TRUE))
# Reshape the data so that conditions are in the middle
reshaped_df <- summary_df %>%
pivot_longer(cols = c(mean_reaction_time, overall_accuracy), names_to = "metric", values_to = "value") %>%
pivot_wider(names_from = condition, values_from = value)
# Output the reshaped table
reshaped_df
# using across
magic_ball %>%
group_by(condition) %>%
summarise(across(c(rt), mean, .names = "mean_{col}"),
overall_accuracy = mean(correct, na.rm = TRUE)) %>%
relocate(condition, .before = mean_reaction_time)
# without using across
magic_ball %>%
group_by(condition) %>%
summarise(
mean_reaction_time = mean(mean_reaction_time),
overall_accuracy = mean(correct == TRUE)
)
# without using across
magic_ball %>%
group_by(condition) %>%
summarise(
mean_reaction_time = mean(mean_reaction_time),
overall_accuracy = mean(correct == TRUE)
)%>%
select(condition, mean_reaction_time, overall_accuracy
# without using across
magic_ball %>%
group_by(condition) %>%
summarise(
mean_reaction_time = mean(mean_reaction_time),
overall_accuracy = mean(correct == TRUE)
)%>%
select(condition, mean_reaction_time, overall_accuracy)
# without using across
magic_ball %>%
group_by(condition) %>%
summarise(
mean_reaction_time = mean(mean_reaction_time),
overall_accuracy = mean(correct == TRUE)
)%>%
select(mean_reaction_time,condition, overall_accuracy)
# using across
magic_ball %>%
group_by(condition) %>%
summarise(across(c(rt), mean, .names = "mean_reaction_time"),
overall_accuracy = mean(correct)) %>%
select(condition, mean_reaction_time, overall_accuracy)
# using across
magic_ball %>%
group_by(condition) %>%
summarise(across(c(rt), mean, .names = "mean_reaction_time"),
overall_accuracy = mean(correct)) %>%
select(mean_reaction_time, condition, overall_accuracy)
# using across
magic_ball %>%
group_by(condition) %>%
summarise(across(c(rt), mean, .names = "mean_reaction_time",
overall_accuracy = mean(correct))) %>%
select(mean_reaction_time, condition, overall_accuracy)
# using across
magic_ball %>%
group_by(condition) %>%
summarise(across(c(rt,correct), mean, .names = "mean_reaction_time","overall_accuracy",
)) %>%
select(mean_reaction_time, condition, overall_accuracy)
library(tidyverse)
# using across
magic_ball %>%
group_by(condition) %>%
summarise(across(c(rt, correct), mean, .names = "mean_{col}")) %>%
rename(overall_accuracy = mean_correct) %>%
select(condition, mean_rt, overall_accuracy)
# using across
magic_ball %>%
group_by(condition) %>%
summarise(across(c(rt, correct), mean, .names = "react_time", "overall_accuracy")) %>%
rename(overall_accuracy = mean_correct) %>%
select(condition, mean_rt, overall_accuracy)
# using across
magic_ball
group_by(condition) %>%
summarise(across(c(rt, correct), mean, .names = "mean_{col}")) %>%
rename(overall_accuracy = mean_correct,
) %>%
select(condition, mean_rt, overall_accuracy)
# using across
magic_ball%>%
group_by(condition) %>%
summarise(across(c(rt, correct), mean, .names = "mean_{col}")) %>%
rename(overall_accuracy = mean_correct) %>%
select(condition, mean_rt, overall_accuracy)
# using across
magic_ball%>%
group_by(condition) %>%
summarise(across(c(rt, correct), mean, .names = "mean_{col}")) %>%
rename(overall_accuracy = mean_correct) %>%
select( mean_rt,condition, overall_accuracy)
# without using across
magic_ball %>%
group_by(condition) %>%
summarise(
mean_rt = mean(mean_reaction_time),
overall_accuracy = mean(correct == TRUE)
)%>%
select(mean_rt,condition, overall_accuracy)
# without using across
magic_ball %>%
group_by(condition) %>%
summarise(
mean_rt = mean(mean_reaction_time),
overall_accuracy = mean(correct)
)%>%
select(mean_rt,condition, overall_accuracy)
# without using across
magic_ball %>%
group_by(condition) %>%
summarise(
mean_rt = mean(rt),
overall_accuracy = mean(correct)
)%>%
select(mean_rt,condition, overall_accuracy)
mean_reaction_times <- c()
for (cond in unique_conditions) {
mean_reaction_time <- magic_ball %>%
filter(condition == cond) %>%
summarize(mean_reaction = mean(rt, na.rm = TRUE)) %>%
pull(mean_reaction)
mean_reaction_times <- c(mean_reaction_times, mean_reaction_time)
}
names(mean_reaction_times) <- unique_conditions
mean_reaction_times
